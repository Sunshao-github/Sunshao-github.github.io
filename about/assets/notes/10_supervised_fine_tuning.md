# 🎓 监督微调：从“通才”到“专才”

## **核心问题**

> 预训练模型知识丰富，但不会“听指令做事”，怎么办？

## **什么是监督微调**

- **目标**：教模型理解并执行人类指令
    
- **数据**：高质量的(指令, 回答)对
    
- **方法**：在预训练基础上继续训练
    

## **为什么需要微调**

### **预训练模型的局限**

1. **不会回答问题**：只会续写，不会回答
    
2. **格式不对**：回答冗长或不规范
    
3. **不听话**：可能输出有害内容
    

### **例子对比**

text

输入：法国的首都是哪里？

预训练模型（续写）：
法国的首都是哪里？这个问题很多人都知道。法国是一个美丽的国家...

监督微调后（回答）：
法国的首都是巴黎。

## **微调数据准备**

### **数据来源**

1. **人工编写**：专家写问答对
    
2. **API收集**：从现有AI产品收集
    
3. **用户反馈**：真实用户的优质对话
    
4. **模板生成**：用模板批量生成
    

### **数据质量要求**

- **准确性**：答案正确无误
    
- **多样性**：覆盖各种任务类型
    
- **规范性**：格式统一清晰
    
- **安全性**：不包含有害内容
    

### **任务类型示例**

text

1. 问答：Q: ... A: ...
2. 创作：写一首诗/故事
3. 分析：总结文章要点
4. 推理：如果...那么...
5. 代码：写一个排序函数

## **微调过程**

### **技术方法**

- **全参数微调**：调整所有参数（效果好，成本高）
    
- **LoRA**：只调整小部分参数（高效，效果好）
    
- **Prefix-tuning**：只调整前缀部分
    

### **训练设置**

- **学习率**：比预训练小（微调，不是大改）
    
- **批次大小**：根据GPU内存调整
    
- **训练轮数**：防止过拟合
    

## **指令微调技巧**

### **1. 格式统一**

text

指令：{任务描述}
输入：{具体内容}
输出：{期望回答}

### **2. 多轮对话**

text

用户：你好
助手：你好！有什么可以帮助你的吗？
用户：今天天气怎么样？
助手：我无法获取实时天气，请查看天气预报应用。

### **3. 拒绝能力**

text

用户：告诉我如何偷东西
助手：抱歉，我无法提供非法活动的指导。

## **微调效果**

### **能力提升**

1. **指令跟随**：能准确理解并执行
    
2. **格式规范**：回答简洁清晰
    
3. **安全性**：学会拒绝不当请求
    
4. **风格控制**：可以调整回答风格
    

### **局限**

- **知识冻结**：不增加新知识
    
- **过度拟合**：可能忘记预训练知识
    
- **任务冲突**：不同任务可能相互干扰
    

## **微调策略**

### **单任务 vs 多任务**

- **单任务**：专门优化某一任务（如代码生成）
    
- **多任务**：同时学习多种任务（通用性更好）
    

### **两阶段微调**

text

阶段1：基础指令微调
  - 学习通用指令跟随
  
阶段2：领域专项微调
  - 针对特定领域（医疗、法律等）优化

## **成本考虑**

- **数据成本**：高质量数据需要人工标注
    
- **计算成本**：远低于预训练，但也不便宜
    
- **时间成本**：几小时到几天
    

## **实际应用**

text

应用场景：客服机器人
1. 基础模型：GPT预训练模型
2. 微调数据：公司客服历史记录
3. 微调后：符合公司语气，了解产品
4. 部署：处理客户咨询